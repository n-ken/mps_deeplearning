{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 動機\n",
    "\n",
    "- パラメーターを更新するためには、誤差関数$E(x)$について、各パラメーターにおける勾配を求める必要がある。\n",
    "- 多層パーセプトロンは深いネットワーク構造であり、各パラメーターの偏微分を計算するためには深い入れ子構造の方程式を偏微分する必要があり、計算量が大きくなる。\n",
    "- 誤差逆伝播法(Back Propagation)は、勾配を効率的に求めるためのストラテジーである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notation\n",
    "\n",
    "表記がややこしいと思う場合、ここは飛ばして適宜参照すると良い。\n",
    "\n",
    "### レイヤー\n",
    "\n",
    "$l = 0, \\cdots, L$。ただし、$l=0$は入力を意味する。データがどのレイヤーに属しているかは、上付き添字で示す。   \n",
    "\n",
    "### 入力、重み行列、出力\n",
    "\n",
    "$l-1$層のユニット数を$I$、$l$層のユニット数を$J$とする。第$l-1$層からの入力を次のように定義する。\n",
    "\n",
    "**入力**:   \n",
    "\n",
    "$\\mathbf{z}^{(l-1)} = \\begin{pmatrix}z_1^{(l-1)}\\\\\\vdots\\\\z_I^{(l-1)}\\end{pmatrix}$\n",
    "\n",
    "ただし、$l-1=0$の時は$\\mathbf{z}^{(0)} = \\mathbf{x}$とする。\n",
    "第$l-1$層の入力から第$l$層への出力の計算に用いる重み行列は次のように定義する。\n",
    "\n",
    "\n",
    "**重み行列**:  \n",
    "\n",
    "$\\mathbf{W}^{(l)} = \n",
    "\\begin{pmatrix}\n",
    "w_{00}^{(l)}&\\cdots&w_{0i}^{(l)}&\\cdots&w_{0I}^{(l)}\\\\\n",
    "w_{10}^{(l)}&\\cdots&w_{1i}^{(l)}&\\cdots&w_{1I}^{(l)}\\\\\n",
    "\\vdots&\\ddots&\\vdots&\\ddots&\\vdots\\\\\n",
    "w_{J0}^{(l)}&\\cdots&w_{Ji}^{(l)}&\\cdots&w_{JI}^{(l)}\n",
    "\\end{pmatrix}$\n",
    "\n",
    "ここで$w_{ij}^{(l)}$は、出力$z_{j}^{(l)}$を計算する際に使用する、第$l-1$層の入力$z_{i}^{(l-1)}$にかかる重みである。\n",
    "\n",
    "また、バイアス項を次のように定義する。\n",
    "$b^{(l)} = \\begin{pmatrix}b_0^{(l)}\\\\\\vdots\\\\b_J^{(l)}\\end{pmatrix}$\n",
    "\n",
    "**出力**:   \n",
    "\n",
    "活性化関数適用前は次のように表記する。   \n",
    "$u_j^{(l)} = \\sum_{i} w_{ji}^{(l)}z_{i}^{(l)} + b_j^{(l)}$\n",
    "\n",
    "活性化関数適用後は次のように表記する。   \n",
    "$z_j^{(l)} = f(u_j^{(l)}) = f(\\sum_{i} w_{ji}^{(l)}z_{i}^{(l)} + b_j^{(l)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与えられたデータとパラメーターをもとに、入力から出力を計算する過程を**Feedforward Propagation**と呼ぶ。\n",
    "ある1件のデータについての第$l-1$層の入力から第$l$層の出力を計算は、次のように表現できる。\n",
    "\n",
    "$$\\mathbf{z}^{(l)} = f(\\mathbf{u}^{(l)}) = f(\\mathbf{W}^{(l)}\\mathbf{z}^{(l-1)} + \\mathbf{b}^{(l)})$$\n",
    "\n",
    "例えば、次のようなネットワークの行列計算を考える。\n",
    "\n",
    "![](figure/feedforward1.png)\n",
    "\n",
    "行列演算は、下図のようにイメージすると良い。\n",
    "\n",
    "![](figure/feedforward2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back Propagation\n",
    "\n",
    "誤差関数$E(\\mathbf{z}^{(L)}, \\mathbf{y})$の各パラメーターについての勾配を求める。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 要点\n",
    "\n",
    "Back Propagationの基本的な戦略は、求めたい偏微分$\\partial E(\\mathbf{z}^{(L)}, \\mathbf{y})$を次のように展開することである。\n",
    "\n",
    "$$\\frac{\\partial E(\\mathbf{z}^{(L)}, \\mathbf{y})}{\\partial w_{ij}^{(l)}} = \n",
    "\\frac{\\partial E(\\mathbf{z}^{(L)}, \\mathbf{y})}{\\partial u_{i}^{(l)}}\\frac{\\partial u_{i}^{(l)}}{\\partial w_{ij}^{(l)}}\\tag{1}$$\n",
    "\n",
    "このような合成関数の微分が成立する理由を考えよう。$u_{i}^{(l)}$は、次のような式で計算される。\n",
    "\n",
    "$$u_{i}^{(l)} = \\sum_{j} w_{ij}^{(l)}z_{j}^{(l-1)}$$\n",
    "\n",
    "すなわち、$w_{ij}^{(l)}$についての偏微分を求めたい場合、$w_{ij}^{(l)}$を含む関数は$u_{i}^{(l)}$のみである。したがって、上の式が成立する。(上の行列演算のイメージ図で確認してみると良い。)\n",
    "\n",
    "ここで得た第一項を次のように定義する。\n",
    "$$\\delta_{i}^{(l)} = \\frac{\\partial E(\\mathbf{z}^{(L)}, \\mathbf{y})}{\\partial u_{i}^{(l)}}\\tag{2}$$\n",
    "\n",
    "(2)より、(1)は次のように表せる。\n",
    "\n",
    "$$\\frac{\\partial E(\\mathbf{z}^{(L)}, \\mathbf{y})}{\\partial w_{ij}^{(l)}} = \n",
    "\\delta_{i}^{(l)}\\frac{\\partial u_{i}^{(l)}}{\\partial w_{ij}^{(l)}}\\tag{3}$$\n",
    "\n",
    "### 出力層\n",
    "  \n",
    "$l-1$層の入力が$i(i = 0, \\cdots, I)$、第$l$層(出力層)の出力が$j(j = 0, \\cdots, J)$だとすると、偏微分$\\partial E / \\partial w_{ji}^{(l)}a$は、(1)より次の通りとなる。\n",
    "\n",
    "$$\\frac{\\partial E(\\mathbf{z}^{(L)}, \\mathbf{y})}{\\partial w_{ji}^{(L)}} = \n",
    "\\frac{\\partial E}{\\partial u_j^{(L)}}\\frac{\\partial u_j^{(L)}}{\\partial w_{ji}^{(L)}}$$ \n",
    "\n",
    "上式の第一項、第二項は直接簡単に求めることができる。\n",
    "\n",
    "### 中間層\n",
    "\n",
    "$l - 1$層の入力が$i(i = 0, \\cdots, I)$, 第$l$層の出力が$j(j = 0, \\cdots, J)$, 第$l+1$層の出力が$k(k = 0, \\cdots, K)$がだとする。具体的に考えるため、次のようなネットワークを用いながら説明を行う。\n",
    "\n",
    "![](figure/backprop1.png)\n",
    "\n",
    "偏微分$\\partial E / \\partial w_{ji}^{(l)}$は、(1)、(3)より次の通りである。   \n",
    "\n",
    "$$\\frac{\\partial E(\\mathbf{z}^{(L)}, \\mathbf{y})}{\\partial w_{ji}^{(l)}} = \\delta_{j}^{(l)}\\frac{\\partial u_{j}^{(l)}}{\\partial w_{ji}^{(l)}} = \n",
    "\\frac{\\partial E(\\mathbf{z}^{(L)}, \\mathbf{y})}{\\partial u_{j}^{(l)}}\\frac{\\partial u_{j}^{(l)}}{\\partial w_{ji}^{(l)}}\\tag{4}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ここで第一項は、さらに(4)は次のように展開できる。\n",
    "\n",
    "$$\\frac{\\partial E(\\mathbf{z}^{(L)}, \\mathbf{y})}{\\partial u_{j}^{(l)}} = \n",
    "\\frac{\\partial E}{\\partial u_{0}^{(l + 1)}}\\frac{\\partial u_{0}^{(l + 1)}}{\\partial u_{j}^{(l)}} + \\cdots + \n",
    "\\frac{\\partial E}{\\partial u_{K}^{(l + 1)}}\\frac{\\partial u_{K}^{(l + 1)}}{\\partial u_{j}^{(l)}} = \n",
    "\\sum_{k} \\frac{\\partial E}{\\partial u_{k}^{(l + 1)}}\\frac{\\partial u_{k}^{(l + 1)}}{\\partial u_{j}^{(l)}}\\tag{5}$$\n",
    "\n",
    "具体例で考えると次の通りである。今、$u_j^{(l)} = u_1^{(l)}$を考える。\n",
    "$u_1{(l)}$は下図の通り、それぞれの$u_k^{(l+1)}(k = 0, \\cdots, K)$の計算に使用される。\n",
    "\n",
    "![](figure/backprop2.png)\n",
    "\n",
    "![](figure/backprop3.png)\n",
    "\n",
    "したがって、合成関数の微分によって上式のように展開される。\n",
    "\n",
    "(5)の右辺の第一項は$\\delta_{k}^{(l + 1)}$となる。代入して第二項をさらに展開する。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E(\\mathbf{z}^{(L)}, \\mathbf{y})}{\\partial u_{j}^{(l)}} = \n",
    "\\sum_{k} \\frac{\\partial E}{\\partial u_{k}^{(l + 1)}}\\frac{\\partial u_{k}^{(l + 1)}}{\\partial u_{j}^{(l)}} = \n",
    "\\sum_{k} \\delta_{k}^{(l + 1)}f'(u_{j}^{(l)})w_{kj}^{(l+1)} = \\delta_{j}^{(l)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
